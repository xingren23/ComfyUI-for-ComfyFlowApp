{"3":{"inputs":{"seed":246848693350477,"steps":20,"cfg":8,"sampler_name":"euler","scheduler":"normal","denoise":1,"basic_pipe":["31:3",0],"latent_image":["5",0]},"class_type":"ImpactKSamplerBasicPipe","_meta":{"title":"KSampler (pipe)"}},"4":{"inputs":{"seed":731186732102241,"steps":20,"cfg":8,"sampler_name":"euler","scheduler":"normal","denoise":1,"basic_pipe":["32:3",0],"latent_image":["6",0]},"class_type":"ImpactKSamplerBasicPipe","_meta":{"title":"KSampler (pipe)"}},"5":{"inputs":{"width":512,"height":768,"batch_size":2},"class_type":"EmptyLatentImage","_meta":{"title":"Empty Latent Image"}},"6":{"inputs":{"width":768,"height":512,"batch_size":2},"class_type":"EmptyLatentImage","_meta":{"title":"Empty Latent Image"}},"7":{"inputs":{"samples":["3",1],"vae":["3",2]},"class_type":"VAEDecode","_meta":{"title":"VAE Decode"}},"8":{"inputs":{"images":["7",0]},"class_type":"PreviewImage","_meta":{"title":"Preview Image"}},"9":{"inputs":{"samples":["4",1],"vae":["4",2]},"class_type":"VAEDecode","_meta":{"title":"VAE Decode"}},"10":{"inputs":{"images":["9",0]},"class_type":"PreviewImage","_meta":{"title":"Preview Image"}},"17":{"inputs":{"wildcard":"best quality:1.4, detailed eyes, natural faint smile","Select to add LoRA":"Select the LoRA to add to the text","Select to add Wildcard":"Select the Wildcard to add to the text","basic_pipe":["4",0],"bbox_detector":["20",0],"sam_model_opt":["21",0]},"class_type":"BasicPipeToDetailerPipe","_meta":{"title":"BasicPipe -> DetailerPipe"}},"20":{"inputs":{"model_name":"bbox/face_yolov8m.pt"},"class_type":"UltralyticsDetectorProvider","_meta":{"title":"UltralyticsDetectorProvider"}},"21":{"inputs":{"model_name":"sam_vit_b_01ec64.pth","device_mode":"AUTO"},"class_type":"SAMLoader","_meta":{"title":"SAMLoader (Impact)"}},"23":{"inputs":{"guide_size":360,"guide_size_for":true,"max_size":768,"seed":569397178581702,"steps":20,"cfg":8,"sampler_name":"euler","scheduler":"normal","denoise":0.5,"feather":5,"noise_mask":true,"force_inpaint":false,"bbox_threshold":0.85,"bbox_dilation":10,"bbox_crop_factor":3,"sam_detection_hint":"center-1","sam_dilation":0,"sam_threshold":0.93,"sam_bbox_expansion":0,"sam_mask_hint_threshold":0.7,"sam_mask_hint_use_negative":"False","drop_size":10,"refiner_ratio":0.2,"cycle":1,"inpaint_model":false,"noise_mask_feather":20,"image":["27",0],"detailer_pipe":["17",0]},"class_type":"FaceDetailerPipe","_meta":{"title":"FaceDetailer (pipe)"}},"25":{"inputs":{"images":["23",0]},"class_type":"PreviewImage","_meta":{"title":"Preview Image"}},"27":{"inputs":{"image1":["29",0],"image2":["30",0]},"class_type":"ImpactMakeImageList","_meta":{"title":"Make Image List"}},"28":{"inputs":{"images":["23",1]},"class_type":"PreviewImage","_meta":{"title":"Preview Image"}},"29":{"inputs":{"image":["7",0]},"class_type":"ImpactImageBatchToImageList","_meta":{"title":"Image batch to Image List"}},"30":{"inputs":{"image":["9",0]},"class_type":"ImpactImageBatchToImageList","_meta":{"title":"Image batch to Image List"}},"32:0":{"inputs":{"ckpt_name":"sd15/DreamShaper_v8.safetensors"},"class_type":"CheckpointLoaderSimple","_meta":{"title":"Load Checkpoint"}},"32:1":{"inputs":{"text":"photorealistic:1.4, best quality:1.4, 1girl is walking through street","clip":["32:0",1]},"class_type":"CLIPTextEncode","_meta":{"title":"CLIP Text Encode (Prompt)"}},"32:2":{"inputs":{"text":"low quality:1.4, worst quality:1.4","clip":["32:0",1]},"class_type":"CLIPTextEncode","_meta":{"title":"CLIP Text Encode (Prompt)"}},"32:3":{"inputs":{"model":["32:0",0],"clip":["32:0",1],"vae":["32:0",2],"positive":["32:1",0],"negative":["32:2",0]},"class_type":"ToBasicPipe","_meta":{"title":"ToBasicPipe"}},"31:0":{"inputs":{"ckpt_name":"sd15/majicmixRealistic-v7.safetensors"},"class_type":"CheckpointLoaderSimple","_meta":{"title":"Load Checkpoint"}},"31:1":{"inputs":{"text":"photorealistic:1.4, best quality:1.4, young man and young woman is sitting side by side","clip":["31:0",1]},"class_type":"CLIPTextEncode","_meta":{"title":"CLIP Text Encode (Prompt)"}},"31:2":{"inputs":{"text":"low quality:1.4, worst quality:1.4","clip":["31:0",1]},"class_type":"CLIPTextEncode","_meta":{"title":"CLIP Text Encode (Prompt)"}},"31:3":{"inputs":{"model":["31:0",0],"clip":["31:0",1],"vae":["31:0",2],"positive":["31:1",0],"negative":["31:2",0]},"class_type":"ToBasicPipe","_meta":{"title":"ToBasicPipe"}},"extra":{"workspace_info":{"id":"e2cee44d-d8d3-4b39-89b3-e1fedb8afb7c","name":"multibatch_api"}}}