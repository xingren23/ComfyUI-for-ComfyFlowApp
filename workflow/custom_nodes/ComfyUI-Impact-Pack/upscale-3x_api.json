{
  "3": {
    "inputs": {
      "seed": 497844439624915,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "37",
        0
      ],
      "positive": [
        "37",
        3
      ],
      "negative": [
        "37",
        4
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "sd15/DreamShaper_v8.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "5": {
    "inputs": {
      "width": 304,
      "height": 512,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "6": {
    "inputs": {
      "text": "photorealistic:1.4, best quality, realistic, masterpiece, high quality, UHD, shadow, taken by Canon EOS, SIGMA Art Lens 35mm F1.4, ISO 200 Shutter Speed 2000 / ðŸ˜Š, light blue hair, pink hair / t-shirt with print, jeans shorts, casual fashion / ðŸŒ¸, blooming all around, (limited palette), colourful, bright colors, pink bag",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "(low quality:1.4), (worst quality:1.4), bad anatomy",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "9": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "8",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Original"
    }
  },
  "10": {
    "inputs": {
      "upscale_factor": 3,
      "steps": 8,
      "temp_prefix": "",
      "samples": [
        "3",
        0
      ],
      "upscaler": [
        "38",
        0
      ]
    },
    "class_type": "IterativeLatentUpscale",
    "_meta": {
      "title": "Iterative Upscale (Latent/on Pixel Space)"
    }
  },
  "12": {
    "inputs": {
      "samples": [
        "10",
        0
      ],
      "vae": [
        "34",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "14": {
    "inputs": {
      "vae_name": "vae-ft-mse-840000-ema-pruned.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "16": {
    "inputs": {
      "images": [
        "12",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Iterative Latent Upscale x3"
    }
  },
  "17": {
    "inputs": {
      "upscale_factor": 2,
      "steps": 5,
      "temp_prefix": "",
      "pixels": [
        "8",
        0
      ],
      "upscaler": [
        "19",
        0
      ],
      "vae": [
        "34",
        2
      ]
    },
    "class_type": "IterativeImageUpscale",
    "_meta": {
      "title": "Iterative Upscale (Image)"
    }
  },
  "18": {
    "inputs": {
      "images": [
        "17",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Iterative Image Upscale x2"
    }
  },
  "19": {
    "inputs": {
      "scale_method": "nearest-exact",
      "seed": 91700641498577,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 0.38,
      "use_tiled_vae": false,
      "tile_size": 512,
      "basic_pipe": [
        "33",
        0
      ]
    },
    "class_type": "PixelKSampleUpscalerProviderPipe",
    "_meta": {
      "title": "PixelKSampleUpscalerProviderPipe"
    }
  },
  "20": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 392,
      "height": 664,
      "crop": "disabled",
      "samples": [
        "3",
        0
      ]
    },
    "class_type": "LatentUpscale",
    "_meta": {
      "title": "Upscale Latent"
    }
  },
  "22": {
    "inputs": {
      "samples": [
        "24",
        0
      ],
      "vae": [
        "36",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "23": {
    "inputs": {
      "images": [
        "22",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Normal Latent Upscale x1.3"
    }
  },
  "24": {
    "inputs": {
      "seed": 97077957396060,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 0.35,
      "model": [
        "36",
        0
      ],
      "positive": [
        "36",
        3
      ],
      "negative": [
        "36",
        4
      ],
      "latent_image": [
        "20",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "27": {
    "inputs": {
      "scale_method": "nearest-exact",
      "scale_factor": 1.3,
      "use_tiled_vae": false,
      "samples": [
        "3",
        0
      ],
      "vae": [
        "36",
        2
      ]
    },
    "class_type": "LatentPixelScale",
    "_meta": {
      "title": "Latent Scale (on Pixel Space)"
    }
  },
  "29": {
    "inputs": {
      "samples": [
        "30",
        0
      ],
      "vae": [
        "36",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "30": {
    "inputs": {
      "seed": 0,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 0.35,
      "model": [
        "36",
        0
      ],
      "positive": [
        "36",
        3
      ],
      "negative": [
        "36",
        4
      ],
      "latent_image": [
        "27",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "31": {
    "inputs": {
      "images": [
        "29",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Latent Pixel Upscale x1.3"
    }
  },
  "33": {
    "inputs": {
      "model": [
        "4",
        0
      ],
      "clip": [
        "4",
        1
      ],
      "vae": [
        "14",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ]
    },
    "class_type": "ToBasicPipe",
    "_meta": {
      "title": "ToBasicPipe"
    }
  },
  "34": {
    "inputs": {
      "basic_pipe": [
        "33",
        0
      ]
    },
    "class_type": "FromBasicPipe",
    "_meta": {
      "title": "FromBasicPipe"
    }
  },
  "36": {
    "inputs": {
      "basic_pipe": [
        "33",
        0
      ]
    },
    "class_type": "FromBasicPipe",
    "_meta": {
      "title": "FromBasicPipe"
    }
  },
  "37": {
    "inputs": {
      "basic_pipe": [
        "33",
        0
      ]
    },
    "class_type": "FromBasicPipe",
    "_meta": {
      "title": "FromBasicPipe"
    }
  },
  "38": {
    "inputs": {
      "scale_method": "nearest-exact",
      "seed": 180735103488546,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 0.35,
      "use_tiled_vae": false,
      "tile_size": 512,
      "model": [
        "34",
        0
      ],
      "vae": [
        "34",
        2
      ],
      "positive": [
        "34",
        3
      ],
      "negative": [
        "34",
        4
      ]
    },
    "class_type": "PixelKSampleUpscalerProvider",
    "_meta": {
      "title": "PixelKSampleUpscalerProvider"
    }
  },
  "39": {
    "inputs": {
      "scale_method": "nearest-exact",
      "seed": 180735103488546,
      "steps": 20,
      "cfg": 9,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 0.4,
      "use_tiled_vae": false,
      "tile_size": 512,
      "basic_pipe": [
        "33",
        0
      ],
      "upscale_model_opt": [
        "40",
        0
      ]
    },
    "class_type": "PixelKSampleUpscalerProviderPipe",
    "_meta": {
      "title": "PixelKSampleUpscalerProviderPipe"
    }
  },
  "40": {
    "inputs": {
      "model_name": "RealESRGAN_x2plus.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "41": {
    "inputs": {
      "upscale_factor": 3,
      "steps": 3,
      "temp_prefix": "",
      "samples": [
        "3",
        0
      ],
      "upscaler": [
        "39",
        0
      ]
    },
    "class_type": "IterativeLatentUpscale",
    "_meta": {
      "title": "Iterative Upscale (Latent/on Pixel Space)"
    }
  },
  "43": {
    "inputs": {
      "samples": [
        "41",
        0
      ],
      "vae": [
        "34",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "44": {
    "inputs": {
      "images": [
        "43",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Iterative Latent Upscale(ESRGANx2) x3"
    }
  }
}